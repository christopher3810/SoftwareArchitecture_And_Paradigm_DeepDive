
>[!Note]
>네트워크 시스템에서 처리율 제한 장치(rate limiter) 는 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate) 제어하기 위한 장치
>HTTP 예로 들면 장치는 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다.
>API 요청 횟수가 제한 장치에 정의된 임계치(threshold) 넘어서면 추가로 도달한 모든 호출은 처리가 중단(block)된다.

처리율 제한(Rate Limiting)은 시스템을 **보호(과부하/자원 고갈/DoS)** 하고, **비용을 통제(3rd party API 과금/리소스 소모)** 하며, **트래픽의 품질을 일정하게 유지**하기 위한 “운영형 설계 메커니즘”이다.  

“요구사항을 먼저 못 박고 → 개략 설계를 제시 → 상세 설계에서 분산 이슈(경쟁 조건/동기화)와 운영(최적화/모니터링)까지 확장”하는 전개

### 요구사항 범위 설정
---

- **무엇을 제한할 것인가?** (IP / 사용자 ID / 엔드포인트 / 서비스 단위 등)

- **규칙(Throttling rules)은 얼마나 유연해야 하는가?** (다양한 규칙 정의 지원)

- **규모는 어느 정도인가?** (대규모 요청 처리 필요)

- **분산 환경인가?** (여러 서버/프로세스가 공유하는가)

- **배치(Placement)는 어디인가?** (독립 서비스 vs 애플리케이션 내장 vs 미들웨어/게이트웨이)

- **제한되었을 때 사용자에게 알려야 하는가?**

### Placement: Rate Limiter를 어디에 둘 것인가?
---

#### 3.1 클라이언트 측?

클라이언트 측은 **위변조 가능**하고, 모든 클라이언트 구현을 통제하기 어려워 신뢰하기 힘들다.

#### 3.2 서버 측 / 미들웨어(또는 API Gateway)

서버 앞단에 **처리율 제한 미들웨어**를 두고 API 서버로 가는 요청을 통제할 수 있다. 

제한 시 429를 반환한다.  
마이크로서비스 환경에서는 처리율 제한이 **API Gateway** 컴포넌트에 구현되는 경우가 흔하며, 게이트웨이는 rate limit 외에도 인증, SSL termination, IP whitelist 같은 기능을 제공할 수 있다.

#### 3.3 정답은 없다(Decision Guide)

“서버에 둘지, 게이트웨이에 둘지”는 정답이 없고, **기술 스택/조직 역량/목표**에 따라 달라진다.

- 서버 내장: 알고리즘 선택 자유도가 높음(하지만 직접 개발/운영 비용 발생)

- 게이트웨이: 운영 단순화(하지만 선택 가능한 알고리즘/정책이 제한될 수 있음)

### 알고리즘(Algorithm) — 트래픽의을 다루는 방법

대표 알고리즘 5개

- Token Bucket / Leaky Bucket / Fixed Window Counter / Sliding Window Log / Sliding Window Counter

---

#### 4.1 Token Bucket

**핵심 아이디어**: 버킷에 토큰이 주기적으로 채워지고, 요청은 토큰 1개를 소비한다. 토큰이 없으면 요청은 버려진다.

- 파라미터: **버킷 크기**, **토큰 공급률(refill rate)**

- “버킷을 몇 개 두는가?”는 규칙 설계에 따라 달라짐(엔드포인트별/사용자별/IP별/전체 트래픽 공유 등)


**장점**

- 구현이 쉽고 메모리 효율적

- 짧은 시간에 몰리는 burst 트래픽 대응 가능(토큰이 있으면 통과)


**단점**

- 버킷 크기/공급률 튜닝이 까다롭다

---

#### 4.2 Leaky Bucket

**핵심 아이디어**: FIFO 큐에 요청을 넣고, 지정된 처리율(outflow rate)로 일정하게 꺼내 처리한다. 큐가 가득 차면 버린다.

**장점**

- 큐 크기 제한 → 메모리 효율

- 출력이 일정(stable outflow rate)해야 하는 경우 적합


**단점**

- burst에서 큐에 오래된 요청이 쌓여 최신 요청이 버려질 수 있음

- 버킷 크기/처리율 튜닝이 까다로움


---

#### 4.3 Fixed Window Counter

**핵심 아이디어**: 고정 시간 창(window)마다 카운터를 두고, 요청마다 +1. 임계치 도달 시 다음 창까지 거부.

**장점**

- 이해/구현이 쉽고 메모리 효율적


**단점(매우 중요)**

- 윈도 경계(boundary) 부근에서 트래픽이 몰리면, 기대 한도보다 더 많은 요청이 처리될 수 있음(예: 1분 5회 제한인데 겹치면 10회 처리)


---

#### 4.4 Sliding Window Log

**핵심 아이디어**: 요청 타임스탬프를 로그로 저장(보통 Redis sorted set). 요청 시 만료된 타임스탬프 제거 후 추가하고, 로그 크기가 한도 이하면 허용/초과면 거부.

**장점**

- 어느 순간의 윈도를 보더라도 한도를 넘지 않는 “정교한” 제한 가능


**단점**

- 거부된 요청의 타임스탬프까지 보관하므로 메모리 사용량이 커질 수 있음


---

#### 4.5 Sliding Window Counter

**핵심 아이디어**: Fixed Window + Sliding Log의 절충. 이전 윈도의 비중을 섞어 현재 윈도의 요청 수를 추정(예: 3 + 5×70% = 6.5).

**장점**

- 이전 시간대 평균을 반영하여 burst에도 대응

- 메모리 효율이 좋다


**주의**

- 구현 접근이 여러 가지이며(책에서는 한 가지 접근만 소개), 완벽한 해법은 아니고 장단점이 있다.

---

### 5.1 카운터 저장소: DB 말고 “메모리 캐시”

카운터는 디스크 접근이 필요한 DB는 느리므로 부적절하고, 시간 기반 만료 정책을 지원하는 **메모리 캐시**가 적합하다. 예로 Redis가 자주 사용되며 `INCR`, `EXPIRE`를 제공한다.

- INCR: 카운터 +1

- EXPIRE: TTL 설정(만료되면 자동 삭제)


### 5.2 미들웨어 흐름

- 클라이언트 요청 → rate limiting middleware

- middleware가 Redis의 버킷 카운터를 확인

- 한도 도달: 거부

- 한도 미도달: API 서버로 전달 + 카운터 증가

---

### 6.1 처리율 제한 규칙(Rules) 저장/로딩

규칙은 보통 **설정 파일 형태로 디스크에 저장**되고, 작업 프로세스(workers)가 수시로 읽어 캐시에 저장한다.

예시

- messaging/marketing: 하루 5개

- auth/login: 분당 5회

### 6.2 제한된 요청의 처리

한도 제한에 걸리면 HTTP **429 (Too Many Requests)** 반환.  
경우에 따라 제한된 메시지를 **큐에 보관해 나중에 처리**할 수도 있다(예: 주문 요청).

### 6.3 클라이언트에게 제공할 헤더

클라이언트가 “얼마나 남았는지/언제 재시도해야 하는지” 알 수 있도록 응답 헤더를 준다.

- `X-Ratelimit-Remaining`: 윈도 내 남은 요청 수

- `X-Ratelimit-Limit`: 윈도마다 허용 요청 수

- `X-Ratelimit-Retry-After`: 다시 요청 가능한 시점 안내  
    제한 시 429와 함께 `X-Ratelimit-Retry-After`를 반환한다.


---

### 7) 분산 환경 구현(Distributed)

분산/병렬에서 어려운 문제 2가지: **경쟁 조건(race condition)**, **동기화(synchronization)**

### 7.1 경쟁 조건(race condition)

“읽기 → 비교 → 쓰기”가 분리되면 병행성이 큰 환경에서 카운터가 틀어질 수 있다.

- 가장 흔한 해결책은 lock이지만 성능 저하가 크다.

- 대안으로 **Lua script** 또는 **Redis sorted set** 접근을 언급한다.


### 7.2 동기화(synchronization)

여러 Rate Limiter 인스턴스가 있으면, 클라이언트 요청이 다른 인스턴스로 분산될 때 동기화가 필요하다.

- sticky session은 확장성/유연성이 떨어져 추천하지 않는다.

- 더 나은 해법은 **Redis 같은 중앙 집중형 저장소**를 사용하는 것.


---

### 8) 성능 최적화 & 운영(Production Concerns)

#### 8.1 지연시간(latency) 줄이기: edge 활용

데이터센터에서 멀리 떨어진 사용자 지원 시 latency가 늘 수 있어, 트래픽을 가까운 **edge server**로 보내는 방식이 유효하다는 관점을 소개한다.

#### 8.2 최종 일관성(eventual consistency)

제한 장치 간 데이터 동기화에 **최종 일관성 모델**을 고려할 수 있음을 언급한다.

#### 8.3 모니터링

설치 후 효과적으로 동작하는지 확인하기 위해 데이터를 모아야 한다.

---

### 9) 클라이언트 설계 가이드

클라이언트 측에서 할 수 있는 최선의 설계 방향

- **클라이언트 캐시**로 API 호출 수 자체를 줄인다.

- 임계치를 이해하고 짧은 시간에 과도한 요청을 보내지 않는다.

- 예외/에러 처리로 우아한 복구(graceful recovery)

- 재시도(retry) 시 충분한 백오프(back-off)